<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> (KOR) AI Agents 스터디 자료[SNU CL LAB] | JooHun Hyun </title> <meta name="author" content="JooHun Hyun"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joohunhyun.github.io/blog/2024/AI-Agents/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">JooHun</span> Hyun </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">(KOR) AI Agents 스터디 자료[SNU CL LAB]</h1> <p class="post-meta"> Created in December 29, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   ·   <a href="/blog/category/study"> <i class="fa-solid fa-tag fa-sm"></i> study</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Table of Contents</strong></p> <ul> <li><a href="#0-%EB%9E%A9%EB%AF%B8%ED%8C%85-%ED%9A%8C%EC%9D%98%EB%A1%9D">0. 랩미팅 회의록</a></li> <li><a href="#1-ai-agents--introduction">1. AI Agents : Introduction</a></li> <li> <a href="#2-ai-agents--methodology">2. AI Agents : Methodology</a> <ul> <li><a href="#21-%EB%8F%99%EC%9E%91-%EC%88%9C%EC%84%9C">2.1 동작 순서</a></li> <li><a href="#22-%EB%8F%99%EC%9E%91-%EC%9B%90%EB%A6%AC">2.2 동작 원리</a></li> <li><a href="#23-%EC%83%81%ED%98%B8%EC%9E%91%EC%9A%A9">2.3 상호작용</a></li> <li><a href="#24-ai-agent-%EC%A2%85%EB%A5%98">2.4 AI Agent 종류</a></li> </ul> </li> <li> <a href="#3-%EC%8A%A4%ED%84%B0%EB%94%94-%EC%9E%90%EB%A3%8C-%EC%A0%95%EB%A6%AC">3. 스터디 자료 정리</a> <ul> <li><a href="#31-agentic-ai-vs-generative-ai">3.1 Agentic AI vs Generative AI</a></li> <li><a href="#32-agentic-ai-building-autonomous-systems-from-scratch">3.2 Agentic AI: Building Autonomous Systems from Scratch</a></li> <li> <a href="#33-the-landscape-of-emerging-ai-agent-architectures-for-reasoning-planning-and-tool-calling-a-survey">3.3 The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey</a> <ul> <li><a href="#singe-mullti-agent-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%A2%85%EB%A5%98">Singe, Mullti agent 아키텍처 종류</a></li> <li><a href="#key-findings">Key Findings</a></li> </ul> </li> <li><a href="#34-ai-agents-vs-agentic-ai--whats-the-difference-and-why-does-it-matter">3.4 AI Agents vs Agentic AI : What’s the Difference and Why Does It Matter?</a></li> <li><a href="#35-the-emergence-of-ai-agent-architecture">3.5 The Emergence of AI Agent Architecture</a></li> <li><a href="#36-best-multi-ai-agent-frameworks">3.6 Best Multi-AI Agent Frameworks</a></li> <li><a href="#38-anatomy-of-agentic-ai">3.8 Anatomy of Agentic AI</a></li> </ul> </li> <li> <a href="#4-external-research">4. External Research</a> <ul> <li><a href="#anthropic---buildng-effective-agents-%ED%8F%AC%EC%8A%A4%ED%8A%B8-%EC%A0%95%EB%A6%AC">Anthropic - Buildng Effective Agents 포스트 정리</a></li> <li><a href="#%EB%B3%B4%EC%95%88-%EC%9D%B4%EC%8A%88">보안 이슈</a></li> </ul> </li> <li> <a href="#5-%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC">5. 프레임워크</a> <ul> <li><a href="#crewai---ai-agent-%EA%B0%9C%EB%B0%9C%EC%9A%A9">CrewAI - AI agent 개발용</a></li> </ul> </li> </ul> <hr> <h3 id="0-랩미팅-회의록">0. 랩미팅 회의록</h3> <ul> <li> <strong>AI agent 개발</strong> <ul> <li>DAG LLM → 운용하는 과정에서 단순히 채팅형 웹페이지가 아니라 agent chatbot 아키텍처를 추가할 예정.</li> <li> <strong>AI Agent</strong> (발표 등, 누가 할 지 자유롭게 하면 됨) 다음주 화요일/수요일 쯤 줌/슬랙으로 얘기 나누면 됨. <ul> <li>읽고 추가 조사 + 노션 자료/PPT + 발표 (서베이 논문 타고 들어가서, 페이퍼 그래프 사용해서 검색하면 됨) → 공부한 내용 공유</li> </ul> </li> </ul> </li> <li> <strong>서비스 아키텍처 구상</strong> (2월 예정) <ul> <li>백엔드와 프론트엔드 작업 방식을 협의 (같이 또는 따로).</li> <li>AI Agent는 학부생의 역량에 맞춰 개발.</li> <li>발제 → 프로덕션에 넣을 수 있는 것 까지. Capstone 느낌.</li> </ul> </li> <li> <strong>LG AI</strong> <ul> <li>주로 작업할 일은 없고, 일손이 필요할 때 하는 수작업(도움이 필요하면 요청).</li> <li>데이터 전처리+가공이 힘든데 이거를 해볼 예정.</li> <li>작업만 하면 됨. 언어학적인 것을 평가할 예정.</li> </ul> </li> <li> <strong>기타사항</strong> <ul> <li>완전 비대면 근무로, 정해진 기한 내에 주어진 업무 수행.</li> <li>작업 시간은 자유롭게 조정 가능.</li> <li>매주 금요일 오후 2시에 대면 회의 진행.</li> </ul> </li> </ul> <h3 id="1-ai-agents--introduction">1. AI Agents : Introduction</h3> <p>AI agent는 사람의 개입없이 AI가 task 수행을 위한 모든 역할을 수행하는 agent를 의미한다. AI agent는 사용자의 프롬프트 입력 없이, 하위 task를 설계하고, 검토하고, 수행하는 과정(<strong>Self-Prompting</strong>)을 반복하는 특징을 가진다. 변하는 상황에 따라 접근 방식을 스스로 조정하며 목표 달성을 위한 전략을 수립하고 실행한다.</p> <p>AI agent의 요건</p> <ol> <li>작업 실행을 계획하고 사용 가능한 도구를 활용하여 작업을 자율적으로 수행하는 시스템</li> <li>사용자를 대신해 자율적으로 작업을 수행할 수 있는 프로그램</li> <li>인간의 지속적인 입력 필요없이 스스로 생각하고, 결정하고, 행동함</li> </ol> <p>예를 들어, 사용자의 프롬프트가 “<strong>200만원 예산 내로 3박4일 일정으로 일본 여행을 가고 싶어.</strong>“일 경우, AI Agent는:</p> <ul> <li>사용자의 캘린더앱을 확인해 여행 일정 추천</li> <li>skyscanner를 통해 여행 일정에 맞는 항공권 추천</li> <li>숙박 사이트를 통해 예산에 맞는 호텔 검색</li> <li>관광지 웹사이트를 확인해 관광지 운영 시간 등을 확인</li> </ul> <p>기존의 LLM이 성능을 높이기 위해 사용한 기술들:</p> <ol> <li> <strong>RAG (Retrieval-Augmented Generation)</strong><br> RAG는 모델이 자체적으로 답을 생성하는 것뿐만 아니라 외부 지식을 검색하고 이를 답변에 활용할 수 있도록 하는 기술이다. <ul> <li>외부 데이터베이스나 문서에서 관련 정보를 검색(Retrieval)하여 가져온다.</li> <li>검색된 정보를 기반으로 답변을 생성(Generation)한다.<br> 이를 통해 모델은 훈련 데이터에 포함되지 않은 정보나 최신 정보를 활용할 수 있어 보다 정확하고 유용한 답변을 제공할 수 있다.</li> </ul> </li> <li> <strong>Chain of Thought (CoT)</strong><br> Chain of Thought은 복잡한 문제를 단계별로 해결하는 방법론이다. <ul> <li>모델이 한 번에 최종 답을 출력하는 대신, 중간 과정을 명시적으로 표현하며 사고의 흐름을 보여준다.</li> <li>예를 들어, 수학 문제를 풀 때 계산 과정을 순차적으로 나열하는 방식이다.<br> 이는 모델이 복잡한 문제를 더 정확하게 해결할 수 있도록 돕는다.</li> </ul> </li> <li> <strong>Few-shot Prompting</strong><br> Few-shot Prompting은 모델에 몇 가지 예제를 제공하여 작업의 맥락을 이해시키는 기법이다. <ul> <li>예제를 입력 프롬프트에 포함시켜 모델이 특정 작업이나 문제 유형을 학습하지 않아도 수행할 수 있도록 돕는다.</li> <li>이를 통해 모델이 훈련되지 않은 작업에 대해서도 높은 정확도로 수행할 수 있다.</li> </ul> </li> <li> <strong>Vector Search</strong><br> 벡터 검색은 데이터나 문장을 임베딩 벡터로 변환한 후, 유사성을 기반으로 검색하는 기술이다. <ul> <li>모델이 문맥적으로 가장 관련성 높은 정보를 빠르게 찾을 수 있도록 한다.</li> <li>특히, 대규모 데이터베이스에서 적합한 데이터를 검색하는 데 유용하다.<br> 이는 질문-응답 시스템이나 추천 시스템에서 자주 사용된다.</li> </ul> </li> <li> <strong>Memory</strong><br> 메모리 기술은 모델이 이전 대화나 맥락을 기억하도록 만들어, 연속적인 대화를 가능하게 하는 방법이다. <ul> <li>사용자와의 대화 기록이나 모델이 이전에 생성한 내용을 저장하고 참조한다.</li> <li>이를 통해 더 자연스럽고 일관성 있는 대화를 유지할 수 있다.<br> 예를 들어, 사용자가 이전에 언급한 내용을 기반으로 추가 정보를 제공하거나 질문에 답변할 수 있다.</li> </ul> </li> </ol> <p><br></p> <h3 id="2-ai-agents--methodology">2. AI Agents : Methodology</h3> <h4 id="21-동작-순서">2.1 동작 순서</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/16-480.webp 480w,/assets/img/16-800.webp 800w,/assets/img/16-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/16.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ol> <li>environment를 파악하고</li> <li>수집한 정보를 활용하여</li> <li>목표 달성을 위한 계획을 세우고</li> <li>이를 실행함</li> </ol> <h4 id="22-동작-원리">2.2 동작 원리</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/17-480.webp 480w,/assets/img/17-800.webp 800w,/assets/img/17-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/17.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ol> <li>observations를 통해 environment를 파악하고</li> <li>past experiences, abilities, goals/preferencees/prior knowledge를 바탕으로 actions 수행</li> <li>1,2 번 (반복)</li> </ol> <p>용어 정리</p> <ul> <li>environment : agent가 작동하는 영역/도메인 (여행 계획 수립 agent예시의 경우, 사용자의 캘린더, 위치정보, 언어설정, 등)</li> <li>abilities/prior knowledge : 모델이 데이터를 통해 이미 학습한 지식</li> <li>goals/preferences : 사용자의 요청의 목적, 수행할 task들을 agent가 스스로 판단</li> <li>observations : 주어진 환경에 대해 수집한 정보</li> <li>past experiences : Agent가 가진 과거의 경험</li> </ul> <h4 id="23-상호작용">2.3 상호작용</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/18-480.webp 480w,/assets/img/18-800.webp 800w,/assets/img/18-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/18.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h4 id="24-ai-agent-종류">2.4 AI Agent 종류</h4> <p>단순 반응형 에이전트 (Reactive Agent)</p> <ul> <li> <strong>특징</strong>: 과거의 데이터를 저장하지 않고, 현재 환경에서 관찰한 정보를 바탕으로 즉각적인 반응을 보이는 에이전트</li> <li> <strong>예시</strong>: <ul> <li>자동문 시스템: 센서를 통해 사람의 존재를 인식하고 문을 여는 역할 수행</li> <li>온도 조절기: 현재 온도를 기준으로 난방 또는 냉방을 수행</li> </ul> </li> </ul> <p>상태 기반 에이전트 (Model-Based Agent)</p> <ul> <li> <strong>특징</strong>: 현재 상태와 과거 상태를 내부적으로 저장하여 의사결정을 수행하며, 환경에 대한 모델을 사용하여 복잡한 작업을 처리할 수 있음</li> <li> <strong>예시</strong>: <ul> <li>네비게이션 시스템: 목적지와 현재 위치를 바탕으로 최적의 경로를 계산</li> </ul> </li> </ul> <p>목표 지향형 에이전트 (Goal-Based Agent)</p> <ul> <li> <strong>특징</strong>: 목표 중심으로 작동하며, 현재 상태와 목표 상태의 차이를 줄이기 위한 계획을 수립함</li> <li> <strong>예시</strong>: <ul> <li>로봇 청소기: 방의 청소가 필요한 위치를 탐지하고 효율적으로 움직임</li> <li>물류 로봇: 특정 지점에 물건을 운반하는 작업을 수행</li> </ul> </li> </ul> <p>유틸리티 기반 에이전트 (Utility-Based Agent)</p> <ul> <li> <strong>특징</strong>: 목표 달성뿐만 아니라 목표 달성의 “질”을 고려하여 유틸리티 함수(만족도, 이익 등)를 기반으로 최적의 선택을 수행함</li> <li> <strong>예시</strong>: <ul> <li>자율주행 차량: 안전, 시간, 연료 효율성을 동시에 고려하여 경로 선택</li> <li>추천 시스템: 사용자 선호도에 따라 최적의 옵션을 추천</li> </ul> </li> </ul> <p>학습 에이전트 (Learning Agent)</p> <ul> <li> <strong>특징</strong>: 경험을 통해 학습하고 시간이 지남에 따라 성능을 점진적으로 개선하며, 학습 요소, 성능 요소, 비평 요소, 문제 생성기를 포함한 구성 요소로 작동</li> <li> <strong>예시</strong>: <ul> <li>AlphaGo: 체스 또는 바둑과 같은 게임을 스스로 학습하고 개선</li> <li>챗봇: 사용자와의 대화 기록을 기반으로 점진적으로 대화 능력 향상</li> </ul> </li> </ul> <p>다중 에이전트 시스템 (Multi-Agent System)</p> <ul> <li> <strong>특징</strong>: 여러 에이전트가 협력하거나 경쟁하며 목표를 달성하는 시스템으로, 각 에이전트는 독립적으로 작동하며 상호작용을 통해 복잡한 문제를 해결함</li> <li> <strong>예시</strong>: <ul> <li>스마트 그리드: 전력 분배를 최적화하는 시스템</li> <li>온라인 게임 AI: 다수의 캐릭터 간 협력 및 경쟁 (예: Pacman)</li> </ul> </li> </ul> <p>하이브리드 에이전트 (Hybrid Agent)</p> <ul> <li> <strong>특징</strong>: 위에서 언급된 여러 종류의 에이전트를 조합하여 설계된 시스템으로, 복잡한 문제 해결을 위해 다양한 접근 방식을 사용함</li> <li> <strong>예시</strong>: <ul> <li>자율주행 차량: 감지(단순 반응형)와 경로 계획(목표 지향형)을 동시에 수행</li> <li>인공지능 비서(Siri, Alexa): 학습 및 목표 지향형 기능을 결합</li> </ul> </li> </ul> <p><br></p> <h3 id="3-스터디-자료-정리">3. 스터디 자료 정리</h3> <h4 id="31-agentic-ai-vs-generative-ai">3.1 Agentic AI vs Generative AI</h4> <p>TL;DR : <strong>Agentic Workflow</strong>는 Zero-shot보다 훨씬 더 높은 정확도를 보인다.</p> <ul> <li> <strong>LLMs</strong>: 입력된 패턴에 반응하며 작동하는 시스템</li> <li> <strong>Agentic AI</strong>: 자율성, 목표 지향적 행동, 학습 및 환경 인식을 통해 지속적인 문제 해결 능력이 필요한 문제도 해결 가능</li> <li> <strong>Agentic AI의 특징</strong> <ul> <li>autonomy</li> <li>goal directed behavior</li> <li>learning from actions and experiences</li> <li>Environmental Perception : AI must understand its environment</li> </ul> </li> </ul> <p>Andrew Ng은 코딩 작업에 있어서 Agentic Workflow의 우수성을 입증하기 위해 케이스 스터디를 진행한 바 있다.<strong>HumanEval coding benchmark</strong>를 벤치마크로 사용해 다음과 같은 실험을 진행했다.</p> <ul> <li> <strong>Zero-shot prompting</strong>: 추가 가이던스(prompting) 없이 문제를 해결하도록 요청하는 방법 <ul> <li>GPT-3.5: 48% 정확도</li> <li>GPT-4: 67% 정확도</li> </ul> </li> <li> <strong>Agentic Workflow</strong>: 작업을 이해, 코딩, 테스트 및 디버깅 등의 단계로 나누어 AI가 반복적으로 개선하도록 설계 <ul> <li>GPT-3.5가 GPT-4보다 우수한 성과를 보임</li> </ul> </li> </ul> <h4 id="32-agentic-ai-building-autonomous-systems-from-scratch">3.2 Agentic AI: Building Autonomous Systems from Scratch</h4> <p><strong>MAS 예시 소스코드</strong>: <a href="https://github.com/zaai-ai/lab" rel="external nofollow noopener" target="_blank">GitHub 코드</a></p> <p>Agentic AI의 필수 구성 요소 (클래스 2개를 작성해야 함)</p> <ol> <li> <strong>Agent</strong> <ul> <li> <strong>LLM</strong>: GPT-4 등</li> <li> <strong>Role</strong>: 정보 처리, 데이터베이스 조회, 상호작용 조정</li> <li> <strong>Backstory</strong>: 현재 환경에 대한 사전 지식</li> <li> <strong>Goal</strong>: 에이전트의 목표</li> </ul> </li> <li> <strong>Task</strong> <ul> <li> <strong>Description</strong>: 수행할 작업과 목표 설명</li> <li> <strong>Output</strong>: 출력 형식 정의 (예: 텍스트, JSON, HTML)</li> </ul> </li> </ol> <h4 id="33-the-landscape-of-emerging-ai-agent-architectures-for-reasoning-planning-and-tool-calling-a-survey">3.3 The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey</h4> <p>현재 복잡한 작업을 해결하는 데 단일 에이전트 시스템이 더 적합한지 다중 에이전트 시스템이 더 적합한지에 대한 논의가 진행 중이다.</p> <ul> <li>Reasoning</li> <li>Planning <ul> <li>task decomposition, multi-plan selection, external module-aided planning, reflection and refinement and memory-augmented planning</li> <li>Plan Like a Graph (PLaG) is an approach that represents plans as directed graphs, with multiple steps being executed in parallel</li> </ul> </li> <li>Effective Tool Calling <ul> <li>Tools enable the agent to interact with external data sources, send or retrieve information from existing APIs</li> <li>Multi-agent patterns can address the issues of parallel tasks and robustness since individual agents can work on individual subproblems</li> </ul> </li> </ul> <p>한글 번역</p> <p>Agent를 잘 개발하기 위해서는 다음이 필요하다.</p> <ul> <li><strong>추론(Reasoning)</strong></li> <li> <strong>계획(Planning)</strong> <ul> <li>작업 분해(Task Decomposition), 다중 계획 선택(Multi-Plan Selection), 외부 모듈을 활용한 계획(External Module-Aided Planning), 반성 및 정제(Reflection and Refinement), 기억 증강 계획(Memory-Augmented Planning)</li> <li> <strong>Plan Like a Graph, PLaG</strong>: 이 접근 방식은 계획을 방향 그래프(directed graph)로 표현하며, 여러 단계를 병렬로 실행하는 방식</li> </ul> </li> <li> <strong>도구 호출(Effective Tool Calling)</strong> <ul> <li>도구는 에이전트가 외부 데이터 소스와 상호작용하거나 기존 API를 통해 정보를 송수신하는 데 도움을 준다.</li> <li>다중 에이전트 패턴은 개별 에이전트가 각각의 하위 문제를 처리할 수 있어 병렬 작업 및 안정성 문제를 해결할 수 있습니다.</li> </ul> </li> </ul> <h5 id="singe-mullti-agent-아키텍처-종류">Singe, Mullti agent 아키텍처 종류</h5> <p><strong>Single-Agent 아키텍처 종류</strong></p> <ul> <li>ReAct (Reason + Act) <ul> <li>The agent first writes a thought about the given task. It then performs an action based on that thought, and the output is observed. This cycle can repeat until the task is complete</li> <li>When evaluated on the HotpotQA dataset, the ReAct method only hallucinated 6% of the time, compared to 14% using the chain of thought (CoT) method</li> <li>the model can repetitively generate the same thoughts and actions and fail to create new thoughts to provoke finishing the task and exiting the ReAct loop.</li> <li>Incorporating human feedback during the execution of the task would likely increase its effectiveness and applicability in real-world scenarios</li> </ul> </li> <li>RAISE <ul> <li>RAISE is built upon the ReAct method, with the addition of a memory mechanism that mirrors human short-term and long-term memory. It does this by using a scratchpad for short-term storage and a dataset of similar previous examples for long-term storage.</li> <li>Improves the agent’s ability to retain context in longer conversations</li> <li>Issues: First, RAISE struggles to understand complex logic, limiting its usefulness in many scenarios. Additionally, RAISE agents often hallucinated with respect to their roles or knowledge</li> </ul> </li> <li>Reflexion <ul> <li>Reflexion is a single-agent pattern that uses self-reflection through linguistic feedback. By utilizing metrics such as success state, current trajectory, and persistent memory, this method uses an LLM evaluator to provide</li> <li>specific and relevant feedback to the agent. This results in an improved success rate as well as reduced hallucination compared to Chain-of-Thought and ReAct.</li> <li>Reflexion is susceptible to “non-optimal local minima solutions”. It also uses a sliding window for long-term memory, rather than a database. This means that the volume of long-term memory is limited by the token limit of the language model.</li> </ul> </li> <li>AutoGPT + P <ul> <li>AutoGPT + P (Planning) is a method that addresses reasoning limitations for agents that command robots in natural language [1]. AutoGPT+P combines object detection and Object Affordance Mapping (OAM) with a planning system driven by a LLM. This allows the agent to explore the environment for missing objects, propose alternatives, or ask the user for assistance with reaching its goal.</li> </ul> </li> <li>LATS <ul> <li>Language Agent Tree Search (LATS) is a single-agent method that synergizes planning, acting, and reasoning by using trees. This technique, inspired by Monte Carlo Tree Search, represents a state as a node and taking an action as traversing between nodes. It uses LM-based heuristics to search for possible options, then selects an action using a state evaluator.</li> <li>often uses more computational resources and takes more time to complete than other single-agent methods</li> </ul> </li> </ul> <p>한글 번역</p> <p>ReAct (Reason + Act)</p> <ul> <li>에이전트는 주어진 작업에 대해 먼저 생각을 작성하고, 그 생각에 기반한 행동을 수행한 후 결과를 관찰합니다. 이 사이클은 작업이 완료될 때까지 반복될 수 있습니다.</li> <li>HotpotQA 데이터셋에서 평가한 결과, ReAct 방법은 체인 오브 쿼트(CoT) 방법에 비해 6%만 허위 생성(hallucination)을 했고, CoT 방법은 14%의 허위 생성이 있었습니다.</li> <li>모델은 반복적으로 같은 생각과 행동을 생성하며, 새로운 생각을 만들어 작업을 완료하거나 ReAct 루프를 종료하지 못할 수 있습니다.</li> <li>작업 실행 중 인간 피드백을 통합하면 실제 상황에서 효과성과 적용 가능성이 증가할 수 있습니다.</li> </ul> <p>RAISE</p> <ul> <li>RAISE는 ReAct 방법을 기반으로 하며, 인간의 단기 및 장기 기억을 반영하는 기억 메커니즘을 추가한 방법입니다. 이는 단기 저장을 위한 스크래치패드와 유사한 이전 예제들로 구성된 장기 저장 데이터를 사용합니다.</li> <li>에이전트의 긴 대화에서 맥락을 유지하는 능력을 향상시킵니다.</li> <li>문제점: RAISE는 복잡한 논리를 이해하는 데 어려움을 겪어 많은 시나리오에서 유용성이 제한됩니다. 또한, RAISE 에이전트는 종종 자신의 역할이나 지식에 대해 허위 정보를 생성하는 경향이 있습니다.</li> </ul> <p>Reflexion</p> <ul> <li>Reflexion은 언어적 피드백을 통해 자기 반성을 사용하는 단일 에이전트 패턴입니다. 성공 상태, 현재 진행 경로, 지속적인 기억과 같은 메트릭스를 활용하여, LLM 평가기를 사용해 에이전트에게 구체적이고 관련성 있는 피드백을 제공합니다.</li> <li>이 방법은 Chain-of-Thought와 ReAct에 비해 성공률이 향상되고 허위 생성이 감소합니다.</li> <li>Reflexion은 “비최적의 지역 최솟값 솔루션”에 취약할 수 있습니다. 또한, 장기 기억을 위한 데이터베이스 대신 슬라이딩 윈도우를 사용하므로 언어 모델의 토큰 제한에 의해 장기 기억 용량이 제한됩니다.</li> </ul> <p>AutoGPT + P</p> <ul> <li>AutoGPT + P(Planning)은 자연어로 로봇을 제어하는 에이전트의 추론 한계를 해결하는 방법입니다. AutoGPT+P는 객체 탐지 및 객체 용도 매핑(Object Affordance Mapping, OAM)을 LLM 기반의 계획 시스템과 결합하여, 에이전트가 환경을 탐색해 누락된 객체를 찾아 대안을 제시하거나 목표 달성에 도움을 주기 위해 사용자에게 요청할 수 있도록 합니다.</li> </ul> <p>LATS</p> <ul> <li>Language Agent Tree Search (LATS)는 계획, 행동, 추론을 트리를 사용하여 시너지 효과를 내는 단일 에이전트 방법입니다. 이 기법은 몬테카를로 트리 탐색(Monte Carlo Tree Search)에 영감을 받아 상태를 노드로, 행동을 노드 간 이동으로 나타냅니다. LM 기반의 휴리스틱을 사용하여 가능한 옵션을 검색하고, 상태 평가기를 사용해 행동을 선택합니다.</li> <li>다른 단일 에이전트 방법에 비해 자원을 더 많이 사용하고 time complexity가 더 길다.</li> </ul> <p><strong>Multi-Agent 아키텍처 종류</strong></p> <p>Embodied LLM Agents</p> <ul> <li>This architecture contains a vertical component through the leader agent, as well as a horizontal component from the ability for agents to converse with other agents besides the leader</li> <li>Agent teams with an organized leader complete their tasks nearly 10% faster than teams without a leader.</li> <li>Agents spent most of their time giving orders to one another (~50% of communication), splitting their remaining time between sharing information, or requesting guidance</li> </ul> <p>DyLAN</p> <ul> <li>Dynamic LLM-Agent Network (DyLAN) framework creates a dynamic agent structure that focuses on complex tasks like reasoning and code generation</li> </ul> <p>AgentVerse</p> <ul> <li>AgentVerse contains four primary stages for task execution: recruitment, collaborative decision making, independent action execution, and evaluation. This can be repeated until the overall goal is achieved.</li> <li>The researchers found that horizontal teams are generally best suited for collaborative tasks like consulting, while vertical teams are better suited for tasks that require clearer isolation of responsibilities for tool calling</li> </ul> <p>MetaGPT</p> <ul> <li>Many multi-agent architectures allow agents to converse with one another while collaborating on a common problem</li> <li>MetaGPT addresses the issue of unproductive chatter amongst agents by requiring agents to generate structured outputs like documents and diagrams instead of sharing unstructured chat messages</li> </ul> <p>한글 번역</p> <p>Embodied LLM Agents</p> <ul> <li>이 아키텍처는 리더 에이전트를 통한 수직적인 요소와, 에이전트들이 리더 외에도 다른 에이전트들과 대화할 수 있는 수평적인 요소를 결합합니다.</li> <li>조직된 리더를 가진 에이전트 팀은 리더가 없는 팀보다 작업을 약 10% 더 빠르게 완료합니다.</li> <li>에이전트들은 대부분의 시간을 서로에게 명령을 내리는 데 사용하며(~50%의 커뮤니케이션), 나머지 시간은 정보를 공유하거나 지침을 요청하는 데 씁니다.</li> </ul> <p>DyLAN</p> <ul> <li> <strong>Dynamic LLM-Agent Network (DyLAN)</strong> 프레임워크는 추론이나 코드 생성과 같은 복잡한 작업에 집중하는 동적 에이전트 구조를 생성합니다.</li> </ul> <p>AgentVerse</p> <ul> <li> <strong>AgentVerse</strong>는 작업 실행을 위한 네 가지 주요 단계로 구성됩니다: 모집, 협력적 의사결정, 독립적 행동 실행, 그리고 평가. 이 과정은 전체 목표가 달성될 때까지 반복될 수 있습니다.</li> <li>연구자들은 horizontal한 팀이 상담과 같은 협력적인 작업에 적합하고, vertical한 팀은 도구 호출을 위한 책임 분리가 더 명확한 작업에 적합하다고 발견했습니다.</li> </ul> <p>MetaGPT</p> <ul> <li>많은 <strong>multi-agent</strong> 아키텍처는 에이전트들이 공통의 문제를 해결하며 서로 대화할 수 있게 합니다.</li> <li>그러나, 서로 메세지를 주고 받을 수 있는 아키텍처를 만들면 비생산적인 대화가 오갈 수 있다 -&gt; 효율성 저하</li> <li> <strong>MetaGPT</strong>는 에이전트들 간의 비생산적인 대화를 해결하기 위해, 에이전트들이 구조화된 출력물(예: 문서, 다이어그램)을 생성하도록 요구하며, 비구조적(이건 좀 아니지 않냐? 식의)인 메시지를 공유하지 않도록 한다.</li> </ul> <h5 id="key-findings">Key Findings</h5> <p>단일 에이전트 vs 다중 에이전트 아키텍처</p> <ul> <li> <strong>Single-agent</strong>는 도구가 명확히 정의되고 프로세스가 잘 정립된 작업에 적합합니다. 또한 구현이 더 간단하고, 다른 에이전트의 피드백이나 불필요한 대화가 없다는 장점이 있습니다. 하지만, 추론과 정제 능력이 부족하다면 실행 루프에 갇혀 목표를 달성하지 못할 수 있습니다.</li> <li> <strong>Multi-agent</strong>는 여러 인물의 피드백이 중요한 작업에 적합합니다. 예를 들어, 문서 생성 시 한 에이전트가 다른 에이전트에게 피드백을 제공하는 방식입니다. 또한 다중 에이전트 시스템은 작업이나 워크플로우의 병렬 처리가 필요한 경우 유용합니다. 예시가 제공되지 않은 경우, 다중 에이전트가 단일 에이전트보다 더 잘 수행된다고 합니다.</li> </ul> <p>에이전트들의 Asynchronous Task Execution</p> <ul> <li> <strong>Single-agent</strong>는 여러 비동기 호출을 동시에 시작할 수 있지만, 각 작업을 순차적으로 계획하고 실행해야 하므로 진정한 병렬적인 처리가 어렵습니다.</li> <li> <strong>Multi-agent</strong>는 각 에이전트가 독립적으로 작업을 수행할 수 있어 더 유연하고 동적인 작업 분배가 가능하며, 개별 에이전트가 다른 에이전트의 작업 상태에 방해받지 않고 진행할 수 있습니다.</li> </ul> <p>피드백과 인간 감독(human oversight)의 영향</p> <ul> <li>에이전트가 복잡한 문제를 해결할 때, 첫 시도에서 완벽한 해결책을 제공하기는 어려우며, 반복적인 피드백과 정제가 필수적입니다. 피드백을 통해 에이전트는 더 나은 방향으로 수정할 가능성이 높아집니다.</li> <li> <strong>Human oversight</strong>는 에이전트의 반응을 인간의 기대에 맞게 조정하여 비효율적이거나 잘못된 접근을 방지합니다. 인간의 검증과 피드백이 포함된 에이전트 아키텍처는 더 신뢰할 수 있고 안정적인 결과를 제공합니다.</li> </ul> <p>Challenges with Group Conversations and Information Sharing</p> <ul> <li> <strong>Multi-agent</strong> 아키텍처는 에이전트 간 메시지를 공유하는 과정에서 문제가 발생할 수 있습니다. 불필요한 대화가 에이전트의 추론 능력과 작업 실행을 방해할 수 있으며, 이는 팀 효율성을 낮춥니다.</li> <li> <strong>Vertical architecture</strong>에서는 역할 분담이 명확하여 방해 요소를 줄일 수 있지만, 중요한 정보가 제대로 전파되지 않으면 혼란이나 허위 생성이 발생할 수 있습니다.</li> </ul> <p>Impact of Role Definition and Dynamic Teams</p> <ul> <li> <strong>Role definition</strong>은 단일 및 다중 에이전트 아키텍처에서 중요한 요소입니다. 역할 정의는 에이전트가 주어진 작업에 집중하고, 불필요한 역할을 피하게 하며, 과도한 허위 생성도 방지합니다.</li> <li> <strong>Dynamic teams</strong>는 작업의 필요에 따라 에이전트를 적절히 투입하고 제거하는 방식으로 효과적인 팀 작업을 지원합니다.</li> </ul> <h4 id="34-ai-agents-vs-agentic-ai--whats-the-difference-and-why-does-it-matter">3.4 AI Agents vs Agentic AI : What’s the Difference and Why Does It Matter?</h4> <p>TL;DR : <strong>Agentic AI와 AI Agents의 차이점</strong>에 대한 글</p> <p>AI Agents vs Agenic AI</p> <ul> <li> <strong>자율성</strong>: Agentic AI는 독립적이고 지속적인 의사결정 가능</li> <li> <strong>상호작용</strong>: AI Agents는 주로 사용자의 명령에 따라 작동</li> </ul> <p>예시</p> <ul> <li> <strong>Agentic AI</strong>: 자율주행 자동차 (테슬라 FSD), 아마존 창고 로봇</li> <li> <strong>AI Agents</strong>: 고객 서비스 챗봇, GitHub Copilot</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/19-480.webp 480w,/assets/img/19-800.webp 800w,/assets/img/19-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/19.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h4 id="35-the-emergence-of-ai-agent-architecture">3.5 The Emergence of AI Agent Architecture</h4> <p>TL;DR : LAM, Model Orchestration, Vision-지원 언어 모델, function calling을 사용하면, 에이전트는 문제 해결, 디지털 환경 (digital landscape) 탐색, 및 자율적인 학습 능력을 가질 수 있게 된다.</p> <p>주요 개념</p> <ul> <li> <strong>Retrieval-Augmented Generation (RAG)</strong>: 작은 언어 모델(SLM)을 보완하여 큰 언어 모델과 유사한 성능 제공</li> <li> <strong>Model Orchestration</strong>: SLM을 결합하여 특정 작업을 지원함</li> <li> <strong>Function calling</strong> : 대형 언어 모델(LLM)의 기능을 텍스트 생성 기증을 넘어 확장성을 제공함</li> <li> <strong>LAM(대형 행동 모델)</strong> : 단순한 언어 생성을 넘어 실제 있을 법한 시나리오에서 의미 있는 행동을 수행할 수 있도록 설계되었다. 이를 통해 AI는 데이터베이스 쿼리나 API 호출과 같은 외부 프로세스를 실행할 수 있다.</li> </ul> <h4 id="36-best-multi-ai-agent-frameworks">3.6 Best Multi-AI Agent Frameworks</h4> <p>TL;DR : 멀티 AI 에이전트를 개발할 시 사용할 프레임워크를 추천하는 글</p> <p><strong>추천 프레임워크</strong></p> <ul> <li> <strong>소프트웨어 개발</strong>: AutoGen (Microsoft) <ul> <li>코드 생성 및 복잡한 다중 에이전트 코딩 워크플로우에 가장 적합합니다.</li> </ul> </li> <li> <strong>초보자에게 추천</strong>: OpenAI Swarm, CrewAI <ul> <li>사용자 친화적</li> <li>복잡한 설정 요구 없이 다중 에이전트 AI에 적합함</li> </ul> </li> <li> <strong>복잡한 작업에 최적화</strong>: LangGraph <ul> <li>높은 flexibility 제공하며, 고급 사용자를 위해 설계되어 에이전트의 커스텀 로직과 orchestration을 허용</li> </ul> </li> <li> <strong>오픈소스 LLM</strong>: LangGraph <ul> <li>다양한 API를 지원</li> </ul> </li> <li> <strong>저비용 개발용</strong>: Magentic-One <ul> <li>사전 패키지 설정과 generalist approach를 제공하여 초기 비용을 절감할 수 있다. Swarm과 CrewAI라는 옵션도 있음.</li> </ul> </li> <li> <strong>즉시 적용 가능한 프레임워크</strong>: CrewAI <ul> <li>환경설정이 빠르고</li> <li>사용이 직관적이며</li> <li>신속한 에이전트 생성이 필요할 경우 적합함</li> <li>Swarm과 Magentic-One도 좋으나 커뮤니티 형성이 덜 되어있음</li> </ul> </li> </ul> <h4 id="38-anatomy-of-agentic-ai">3.8 Anatomy of Agentic AI</h4> <p>TL;DR <strong>Agentic AI 아키텍처</strong>와 이를 구현할 때 고려해야 할 점을 다룬다.</p> <p>아키텍처 예시 :</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/20-480.webp 480w,/assets/img/20-800.webp 800w,/assets/img/20-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/20.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>개발 시 고려할 점 :</p> <ul> <li> <strong>모듈화와 확장성</strong>: 복잡한 작업을 처리할 수 있도록 설계해야 함</li> <li> <strong>적응성</strong>: 환경에 따라 학습 및 행동을 개선할 수 있어야 함</li> <li> <strong>멀티모달 상호작용</strong>: 디지털 및 물리적 환경과 상호작용이 되도록 개발해야 함</li> <li> <strong>협력</strong>: 공유 메모리를 활용한 에이전트 간 협력</li> </ul> <h3 id="4-external-research">4. External Research</h3> <h4 id="anthropic---buildng-effective-agents-포스트-정리">Anthropic - Buildng Effective Agents 포스트 정리</h4> <p>클라우드에서는 workflow와 agent를 구분한다. <strong>Workflow</strong>란 LLM과 tools가 사전 정의된 code path를 통해 orchestrate 되는 것을 의미하는 반면, <strong>Agents</strong>는 LLM이 동적으로 자신들의 프로세스와 tool 사용을 정의하고, task 수행을 자율적으로 컨트롤하는 시스템을 의미한다. Agent는 flexibility나 모델-주도-의사결정 과정이 필요한 경우에 사용하고, workflow는 반복적이거나 잘 정의된(well-defined) task를 수행할 때 용의한 시스템이다. 에이전트를 개발할 때 있어서, LangGraph, Rivet, Vellum 등의 프레임워크가 있으나, 이런 프레임워크는 복잡한 layer들을 추가하여 디버깅을 까다롭게 한다. 그럼으로, 클라우드는 LLM API를 직접 사용하여 agentic system을 개발하는 것을 권장한다. 코드 examples는 여기서 확인해볼 수 있다 -&gt; <a href="https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents" rel="external nofollow noopener" target="_blank">클라우드의 cookbook</a>.</p> <p><strong>Prompt Chaining</strong></p> <p>Prompt Chaining 방식은 task가 여러 subtask로 깔끔하게 떨어지는 경우에 사용하는 것을 권장한다. 이 방식의 경우 Tradeoff가 발생하게 되는데, latency&lt;-&gt;accuracy의 tradeoff 관계가 형성된다.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/22-480.webp 480w,/assets/img/22-800.webp 800w,/assets/img/22-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/22.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Routing</strong></p> <p>Routing 방식은 input을 분류하여 다음 작업으로 전달해주는 과정을 의미한다. CS센터 챗봇 개발에 용의한 아키텍처이다. Input(고객 문의) -&gt; 일반 문의/제품 문의/환불 요청 3중 1택 -&gt; Output(챗봇 전달 내용)</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/23-480.webp 480w,/assets/img/23-800.webp 800w,/assets/img/23-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/23.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Orchestrator-Workers</strong></p> <p>Orchestrator-Workers 방식에서는 Central LLM이 task를 동적으로 세분화하여 worker LLM에 이를 넘겨주고 그 결과를 종합한다. 해당 방식은 최종 goal의 하위 task들을 예측할 수 없는 복잡한 작업들에 적합하다. 하위 작업은 미리 정의되지 않고, 특정 입력에 따라 orchestrator가 이를 결정한다.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/24-480.webp 480w,/assets/img/24-800.webp 800w,/assets/img/24-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/24.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Evaluator-optimizer</strong></p> <p>Evaluator-optimizer 방식에서는 LLM call Generator가 응답을 생성하고 이를 LLM Call Evaluator가 받아 Accept하거나, Reject를 할 경우, 평가와 피드백을 제공한다. 반복적으로 수행하는 작업을 한다. LLM Call Evaluator가 응답을 Accept할 떄까지 Loop이 생성된다(exit condition). 해당 방식은 명확한 평가 기준이 있고 반복적인 개선 작업을 통해 측정 가능한 가치가 있을 경우 효과적이다. 예를 들어 웹 서핑을 통해 정보를 수집하기 위해 여러 차례의 검색과 분석이 필요한 복잡한 검색 작업의 경우, Evaluator가 추가 검색이 필요한지 여부를 결정해 검색 정확도를 높힐 수 있다.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/25-480.webp 480w,/assets/img/25-800.webp 800w,/assets/img/25-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/25.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>Agents</strong></p> <p>Agent 방식은 요즘 각광받고 있는 워크플로우이다. Agent의 워크플로우를 요약하자면 다음과 같다. Tools 설계 시 고려할 점 : 에이전트는 tools와 feedback loop에 의존하므로, tools와 관련된 코드를 명확하고 신중하게 설계하는 것이 중요합니다. 또한, Agent의 자율적인 특성은 높은 토큰 비용과 오류의 가능성이 높아짐을 의미한다. 적절한 exit condition를 <strong>무조건</strong> 구현하고, 샌드박스 환경에서 광범위한 테스트를 사전에 수행할 것을 권장함.</p> <ol> <li>Input: 에이전트가 사용자의 명령, 혹은 사용자와의 대화(Q&amp;A)를 통해 작업을 시작하고, 작업을 명확히 정의함.</li> <li>계획 수립 단계: 하위 작업들이 명확히 정의되면, 에이전트들이 계획을 세우고 자율적으로 작업을 진행합니다.</li> <li>실행 단계: 에이전트는 각 단계에서 환경으로부터 “정확한 정보(ground truth)”를 도출해 진행 상황을 평가합니다.</li> <li>사용자와의 상호작용(Optional): 에이전트는 중간 체크포인트나 장애물에 직면했을 때 작동을 멈추고, 사용자로부터 추가 피드백이나 판단을 요청합니다.</li> <li>Completion 단계: 작업이 성공적으로 완료되거나, 사전에 정의된 exit condition이 충족되면 작동울 멈춘다.</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/26-480.webp 480w,/assets/img/26-800.webp 800w,/assets/img/26-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/26.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>다음 자료는 coding Agent의 high-level 워크플로우입니다.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/27-480.webp 480w,/assets/img/27-800.webp 800w,/assets/img/27-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/27.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>최종 설계</strong></p> <p>위에 설명한 워크플로우들을 목적에 맞게 결합할 수 있다. 모든 LLM 기능 개발과 마찬가지로, 성공의 비결은:</p> <ol> <li>구현</li> <li>성능 측정</li> </ol> <p>1번과 2번을 반복하는 것이다. 한 가지를 더 강조하자면, 성능이 확실히 개선되는 경우에만 기능을 추가하는 것을 권장한다.</p> <p><a href="https://www.anthropic.com/research/building-effective-agents" rel="external nofollow noopener" target="_blank">출처</a></p> <h4 id="보안-이슈">보안 이슈</h4> <p>AI가 컴퓨터 화면을 읽게 하여 컴퓨터를 조작하는 자율성 높은 Agentic AI 개발 시 보안 문제가 야기된다. prompt injection는 특정 웝사이트에 어떤 prompt(listener 등)를 끼워넣는 행위를 의미하는데, agentic AI가 이를 실행해버리는 경우도 있다.</p> <h3 id="5-프레임워크">5. 프레임워크</h3> <h4 id="crewai---ai-agent-개발용">CrewAI - AI agent 개발용</h4> <p><a href="https://docs.crewai.com/concepts/flows" rel="external nofollow noopener" target="_blank">official docs</a></p> <p><strong>작동방식</strong></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/21-480.webp 480w,/assets/img/21-800.webp 800w,/assets/img/21-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/21.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p><strong>구성 요소</strong></p> <table> <thead> <tr> <th>구성 요소</th> <th>설명</th> <th>주요 특징</th> </tr> </thead> <tbody> <tr> <td><strong>Crew</strong></td> <td>최상위 조직</td> <td>• AI 에이전트 팀 관리<br>• 워크플로우 감독<br>• 협업 보장<br>• 결과 제공</td> </tr> <tr> <td><strong>AI Agents</strong></td> <td>특화된 팀원</td> <td>• 특정 역할 수행 (연구자, 작가 등)<br>• 지정된 도구 사용<br>• 작업 위임 가능<br>• 자율적 의사결정</td> </tr> <tr> <td><strong>Process</strong></td> <td>워크플로우 관리 시스템</td> <td>• 협업 패턴 정의<br>• 작업 할당 관리<br>• 상호작용 관리<br>• 효율적 실행 보장</td> </tr> <tr> <td><strong>Tasks</strong></td> <td>개별 작업</td> <td>• 명확한 목표 설정<br>• 특정 도구 사용<br>• 전체 프로세스에 기여<br>• 실행 가능한 결과 생산</td> </tr> </tbody> </table> <p><br></p> <p><strong>연동 방식</strong></p> <ol> <li> <strong>Crew</strong>가 전체 운영을 조직화합니다.</li> <li> <strong>AI Agents</strong>는 자신들이 특화된 작업을 수행합니다.</li> <li> <strong>Process</strong>는 원활한 협업을 보장합니다.</li> <li>최종 목표 달성을 위해 <strong>Tasks</strong>를 수행합니다.</li> </ol> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/Al-Folio-%EC%84%A4%EC%B9%98-%EB%B0%A9%EB%B2%95,-%EC%82%AC%EC%9A%A9%EB%B2%95,-%EC%BB%A4%EC%8A%A4%ED%85%80-%EC%82%AC%EC%9A%A9/">(KOR) Github al-folio 설치부터 블로그 테마 변경까지</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/DeepSeek/">(ENG) DeepSeek-R1 Paper Review</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/AutoGPT/">(ENG) AutoGPT Installation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/cs224n-1/">(ENG) CS224n - Lecture 1</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/cs224n-1-copy/">(ENG) CS224n - Lecture 1</a> </li> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 JooHun Hyun. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-projects",title:"projects",description:"An archive of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-kor-github-al-folio-\uc124\uce58\ubd80\ud130-\ube14\ub85c\uadf8-\ud14c\ub9c8-\ubcc0\uacbd\uae4c\uc9c0",title:"(KOR) Github al-folio \uc124\uce58\ubd80\ud130 \ube14\ub85c\uadf8 \ud14c\ub9c8 \ubcc0\uacbd\uae4c\uc9c0",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/Al-Folio-%EC%84%A4%EC%B9%98-%EB%B0%A9%EB%B2%95,-%EC%82%AC%EC%9A%A9%EB%B2%95,-%EC%BB%A4%EC%8A%A4%ED%85%80-%EC%82%AC%EC%9A%A9/"}},{id:"post-eng-deepseek-r1-paper-review",title:"(ENG) DeepSeek-R1 Paper Review",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/DeepSeek/"}},{id:"post-eng-autogpt-installation",title:"(ENG) AutoGPT Installation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/AutoGPT/"}},{id:"post-kor-ai-agents-\uc2a4\ud130\ub514-\uc790\ub8cc-snu-cl-lab",title:"(KOR) AI Agents \uc2a4\ud130\ub514 \uc790\ub8cc[SNU CL LAB]",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/AI-Agents/"}},{id:"post-eng-cs224n-lecture-1",title:"(ENG) CS224n - Lecture 1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs224n-1/"}},{id:"post-eng-cs224n-lecture-1",title:"(ENG) CS224n - Lecture 1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs224n-1-copy/"}},{id:"post-kor-kr-bert-a-small-scale-korean-specific-language-model",title:"(KOR) KR-BERT:A Small-Scale Korean-Specific Language Model",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/KR-BERT-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"}},{id:"post-eng-feature-selection-extraction-and-ensamble-methods",title:"(ENG) Feature Selection, Extraction, and Ensamble Methods",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/feature/"}},{id:"post-eng-training-and-evaluating-deep-networks",title:"(ENG) Training and Evaluating Deep Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"post-eng-rnn-and-lstm",title:"(ENG) RNN and LSTM",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/RNN/"}},{id:"post-eng-mlp-and-dnn",title:"(ENG) MLP and DNN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/MLP-DNN/"}},{id:"post-kor-\uc5f0\uad6c\uc2e4-\uc548\uc804\uad50\uc721-\ubc30\uc18d\ud558\ub294-\ubc29\ubc95",title:"(KOR) \uc5f0\uad6c\uc2e4 \uc548\uc804\uad50\uc721 \ubc30\uc18d\ud558\ub294 \ubc29\ubc95",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/skip-safety-skip-copy/"}},{id:"post-eng-svm-svc",title:"(ENG) SVM, SVC",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/SVM-SVC/"}},{id:"post-kor-vscode-shortcut-keys-macos",title:"(KOR) VsCode Shortcut Keys[MacOS]",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/VsCode-Shortcut-Keys/"}},{id:"post-eng-development-of-artificial-intelligence",title:"(ENG) Development of Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/history-of-ML/"}},{id:"post-kor-\ub9c8\ud06c\ub2e4\uc6b4-\ubb38\ubc95-\uc815\ub9ac",title:"(KOR) \ub9c8\ud06c\ub2e4\uc6b4 \ubb38\ubc95 \uc815\ub9ac",description:"\ub9c8\ud06c\ub2e4\uc6b4 \ubb38\ubc95",section:"Posts",handler:()=>{window.location.href="/blog/2024/markdown-syntax/"}},{id:"post-eng-backpropagation",title:"(ENG) Backpropagation",description:"backpropagation",section:"Posts",handler:()=>{window.location.href="/blog/2024/backpropagation/"}},{id:"post-eng-github-commit-message-conventions",title:"(ENG) Github Commit Message Conventions",description:"gitub commmit message convetions",section:"Posts",handler:()=>{window.location.href="/blog/2024/github-conventions-copy/"}},{id:"post-kor-\ub17c\ubb38-\ub9ac\ubdf0-\ubc29\ubc95\ub860",title:"(KOR) \ub17c\ubb38 \ub9ac\ubdf0 \ubc29\ubc95\ub860",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/journal-reading-methodology/"}},{id:"post-kor-\uc544\ub098\ucf58\ub2e4-venv-\uc124\uc815",title:"(KOR) \uc544\ub098\ucf58\ub2e4 venv \uc124\uc815",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/conda-venv/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-2025-snu-nlp-lab-winter-internship",title:"2025 SNU NLP Lab Winter Internship",description:"2025 \uc11c\uc6b8\ub300\ud559\uad50 \uc790\uc5f0\uc5b4\ucc98\ub9ac \uc5f0\uad6c\uc2e4 \ud65c\ub3d9 \uc815\ub9ac",section:"Projects",handler:()=>{window.location.href="/projects/project1/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>