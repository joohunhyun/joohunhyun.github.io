<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> (작성중)(KOR) KR-BERT:A Small-Scale Korean-Specific Language Model | JooHun Hyun </title> <meta name="author" content="JooHun Hyun"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://joohunhyun.github.io/blog/2024/KR-BERT-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "(작성중)(KOR) KR-BERT:A Small-Scale Korean-Specific Language Model",
            "description": "",
            "published": "December 26, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">JooHun</span> Hyun </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>(작성중)(KOR) KR-BERT:A Small-Scale Korean-Specific Language Model</h1> <p></p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> </nav> </d-contents> <ul> <li> <a href="#1-%EB%85%BC%EB%AC%B8-%EC%9A%94%EC%95%BD">1. 논문 요약</a> <ul> <li><a href="#11-rationale">1.1 Rationale</a></li> <li><a href="#12-methodology-%EC%9A%94%EC%95%BD">1.2 Methodology 요약</a></li> <li><a href="#13-conclusion">1.3 Conclusion</a></li> </ul> </li> <li> <a href="#2-mbert%EC%9D%98-%ED%95%9C%EA%B3%84">2. mBERT의 한계</a> <ul> <li><a href="#21-corpus%EB%A7%90%EB%AD%89%EC%B9%98-domain%EC%9D%98-%ED%95%9C%EA%B3%84">2.1 Corpus(말뭉치) Domain의 한계</a></li> <li><a href="#22-%ED%95%9C%EA%B5%AD%EC%96%B4%EC%9D%98-%EC%96%B8%EC%96%B4%EC%A0%81-%ED%8A%B9%EC%84%B1%EC%9D%84-%EC%B6%A9%EB%B6%84%ED%9E%88-%EA%B3%A0%EB%A0%A4%ED%95%98%EC%A7%80-%EC%95%8A%EC%9D%80-%EC%A0%90">2.2 한국어의 언어적 특성을 충분히 고려하지 않은 점</a></li> <li><a href="#23-%EB%AA%A8%EB%8D%B8%EC%9D%98-%ED%81%AC%EA%B8%B0">2.3 모델의 크기</a></li> </ul> </li> <li> <a href="#3-methodology">3. Methodology</a> <ul> <li><a href="#31-subcharacter-text-representation">3.1 Subcharacter Text Representation</a></li> <li><a href="#32-subword-vocabulary">3.2 Subword Vocabulary</a></li> </ul> </li> <li> <a href="#4-results">4. Results</a> <ul> <li><a href="#masked-lm-accuracy">Masked LM Accuracy</a></li> </ul> </li> <li><a href="#5-related-work--benchmarks">5. Related Work / Benchmarks</a></li> </ul> <hr> <h3 id="1-논문-요약">1. 논문 요약</h3> <p><br></p> <h4 id="11-rationale">1.1 Rationale</h4> <p>Multilingual-BERT(이하 mBERT)는 위키백과의 104개 언어로 된 문서들을 기반으로 학습된 모델이다. 그러나, 모든 언어의 언어적 특성을 학습시킬 수는 없기 때문에 비영어 다운스트림 작업(non-English downstream tasks)에는 정확도가 다소 떨어진 모습을 보인다. <strong>Downstream tasks</strong>란 자연어 처리(NLP)에서 사전 학습된 언어 모델을 활용하여 수행하는 특정 응용 작업 (예: 감정 분석, 개체명 인식, 문장 분류 등)을 의미한다.</p> <p>한국어는 10,000개 이상의 문자(character)를 사용하고, 독어나 불어와 같은 굴절어보다 형태적으로 복잡하다. mBERT에서는 이 가운데 오직 1,187개의 문자만이 포함되었다. 또한, mBERT 모델은 104개의 언어 데이터를 포함하기에 크기가 과도하게 크다는 단점이 존재한다. 그래서, ALBERT나 Distil-BERT처럼 모델을 축소하면서도 성능을 유지하는 방법이 필요하다.</p> <p>요약하자면:</p> <ol> <li>mBERT는 모델 크기가 과도하게 크다.</li> <li>mBERT는 non-English downstream tasks에서 성능이 다소 떨어진다.</li> <li>모델을 축소하면서 성능을 유지하는 한국어 언어모델이 필요하다.</li> </ol> <p>KR-BERT는 이런 점들을 해결하기 위해 고안된 새로운 한국어 언어모델이다.</p> <p><br></p> <h4 id="12-methodology-요약">1.2 Methodology 요약</h4> <p><br></p> <h4 id="13-conclusion">1.3 Conclusion</h4> <ul> <li>KR-BERT는 다음의 downstream tasks들에서 mBERT의 성능을 능가했다. <ul> <li>senti- ment analysis</li> <li>Question-Answering</li> <li>Named Entity Recognition(NER)</li> <li>Paraphrase Detection</li> </ul> </li> <li>KR-BERT는 다른 한국어 모델들에 비해 다운스트림 작업에서 더 좋은 성능을 보이거나 비슷한 성과를 보였다.</li> <li>형태소가 많은 한국어에 맞게 서브-캐릭터 기반 모델과 Bidirectional-WordPiece 토크나이저를 사용하여 적은 자원으로도 효과적인 성능을 달성했다.</li> </ul> <p><br> <br></p> <h3 id="2-mbert의-한계">2. mBERT의 한계</h3> <p><br></p> <h5 id="21-corpus말뭉치-domain의-한계">2.1 Corpus(말뭉치) Domain의 한계</h5> <p>GCamemBERT와 같은 언어별 특화된(Language Specific) BERT 모델들은 법률 데이터, 뉴스 기사 등, 다양한 데이터 소스를 사용하여 학습된 반면, mBERT는 유저들이 직접 작성한 데이터 소스(블로그 글, 댓글, 등)를 사용하지 않고, 위키백과 포스트들의 언어적 특성을 기반으로만 학습되어 언어 사용(limited in its domain with respect to language usage - 직역하면 언어 사용이지만 어휘력일 것이라고 생각됨) 측면에서 한계가 존재한다.</p> <p><br></p> <h5 id="22-한국어의-언어적-특성을-충분히-고려하지-않은-점">2.2 한국어의 언어적 특성을 충분히 고려하지 않은 점</h5> <p>2.2.1 Rare Character Problem</p> <p>라틴 문자 기반 언어는 단어를 문자 단위로 분리하여 처리할 수 있는 반면, 한국어의 언어적 특성상 음절 단위로 처리되어 Out-of-Vocabulary(OoV)가 라틴 문자 기반 언어보다 많을수밖에 없다. 그럼으로, 이런 한국어의 특성을 고려한 새로운 BERT Vocabulary가 필요하다.</p> <p>2.2.2 교착언어에 적합하지 않은 모델</p> <p>교착어(agglutinative language)란 문법적 의미를 전달하기 위해 주로 접사를 단단히 결합하는 언어를 의미한다. 교착어는 형태론적인 복잡성(morphological complexity) 때문에 vocabulary를 표현하기 어렵다. 한국어 역시 교착언어에 해당하며, mBERT는 이 문제를 제대로 처리하지 않은 것으로 보인다.</p> <p>2.2.3 Lack of Meaningful Tokens</p> <p>독일어의 경우, mBERT 모델의 어휘에 명확한 semantic meaning이 없는 subword unit이 포함되어 있었다. 한국어에서도 이와 유사한 문제가 존재했는데, 대부분의 단어가 형태소와 같은 단위가 아닌 단일 문자로 tokenized 되었기 떄문이다. 이 문제를 해결하기 위해, 한국어 텍스트와 한국어의 언어적 특성을 고려한 vocabulary 및 tokenizer를 구현했다.</p> <p><br></p> <h5 id="23-모델의-크기">2.3 모델의 크기</h5> <p>대형 모델들은 많은 양의 dataset, parameter, voabulary를 필요로 한다. mBERT는 167M, RoBERTa는 355M 파라미터를 사용해 자원의 제약을 받기 마련인데, KR-BERT는 적은 parameter와 훈련 데이터를 사용하면서 mBERT와 비슷한 성능을 유지할 수 있었다.</p> <p><br> <br></p> <h3 id="3-methodology">3. Methodology</h3> <p>KR-BERT를 Multilingual BERT, Kor- BERT, 그리고 KoBERT와 비교했다.</p> <p><br></p> <h4 id="31-subcharacter-text-representation">3.1 Subcharacter Text Representation</h4> <p>한국어 텍스트는 Text-&gt; 한글 -&gt; graphemes의 형태로 분해 가능하다. 이런 특성을 반영하기 위해, KR-BERT는 syllable character와 sub-character 두 가지 말뭉치 표현 방식을 사용하여 new vocabulary와 BERT model을 학습시켰다. BPE 알고리즘을 적용하면, 다음과 같은 tokenization이 가능해진다.</p> <p><code class="language-plaintext highlighter-rouge">Example : 뜀(ttwim, "jumping")은 ㄸㅟ(ttwi, "jump")와 ᄆ(m, "-ing")으로 분해될 수 있다</code></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/15-480.webp 480w,/assets/img/15-800.webp 800w,/assets/img/15-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/15.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>KR-BERT 모델은 나머지 벤치마크 모델들과 달리, 음절 문자 이외에도 하위 문자 표현을 사용해 다양한 한국어 동사/형용사의 공통된 특성을 학습할 수 있었다.</p> <p><br></p> <h4 id="32-subword-vocabulary">3.2 Subword Vocabulary</h4> <h3 id="4-results">4. Results</h3> <h4 id="masked-lm-accuracy">Masked LM Accuracy</h4> <h3 id="5-related-work--benchmarks">5. Related Work / Benchmarks</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/13-480.webp 480w,/assets/img/13-800.webp 800w,/assets/img/13-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/13.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/14-480.webp 480w,/assets/img/14-800.webp 800w,/assets/img/14-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/14.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 JooHun Hyun. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-projects",title:"projects",description:"An archive of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"post-kor-vim-\uc0ac\uc6a9\ubc95",title:"(KOR) vim \uc0ac\uc6a9\ubc95",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/vim/"}},{id:"post-kor-github-al-folio-\uc124\uce58\ubd80\ud130-\ube14\ub85c\uadf8-\ud14c\ub9c8-\ubcc0\uacbd\uae4c\uc9c0",title:"(KOR) Github al-folio \uc124\uce58\ubd80\ud130 \ube14\ub85c\uadf8 \ud14c\ub9c8 \ubcc0\uacbd\uae4c\uc9c0",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/Al-Folio-%EC%84%A4%EC%B9%98-%EB%B0%A9%EB%B2%95,-%EC%82%AC%EC%9A%A9%EB%B2%95,-%EC%BB%A4%EC%8A%A4%ED%85%80-%EC%82%AC%EC%9A%A9/"}},{id:"post-eng-deepseek-r1-paper-review",title:"(ENG) DeepSeek-R1 Paper Review",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/DeepSeek/"}},{id:"post-eng-autogpt-installation",title:"(ENG) AutoGPT Installation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/AutoGPT/"}},{id:"post-kor-ai-agents-\uc2a4\ud130\ub514-\uc790\ub8cc-snu-cl-lab",title:"(KOR) AI Agents \uc2a4\ud130\ub514 \uc790\ub8cc[SNU CL LAB]",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/AI-Agents/"}},{id:"post-eng-cs224n-lecture-1",title:"(ENG) CS224n - Lecture 1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs224n-1%EA%B0%95/"}},{id:"post-\uc791\uc131\uc911-kor-kr-bert-a-small-scale-korean-specific-language-model",title:"(\uc791\uc131\uc911)(KOR) KR-BERT:A Small-Scale Korean-Specific Language Model",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/KR-BERT-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"}},{id:"post-eng-feature-selection-extraction-and-ensamble-methods",title:"(ENG) Feature Selection, Extraction, and Ensamble Methods",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/feature/"}},{id:"post-eng-training-and-evaluating-deep-networks",title:"(ENG) Training and Evaluating Deep Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"post-eng-rnn-and-lstm",title:"(ENG) RNN and LSTM",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/RNN/"}},{id:"post-eng-mlp-and-dnn",title:"(ENG) MLP and DNN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/MLP-DNN/"}},{id:"post-kor-\uc5f0\uad6c\uc2e4-\uc548\uc804\uad50\uc721-\ubc30\uc18d\ud558\ub294-\ubc29\ubc95",title:"(KOR) \uc5f0\uad6c\uc2e4 \uc548\uc804\uad50\uc721 \ubc30\uc18d\ud558\ub294 \ubc29\ubc95",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/skip-safety-skip-copy/"}},{id:"post-eng-svm-svc",title:"(ENG) SVM, SVC",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/SVM-SVC/"}},{id:"post-kor-vscode-shortcut-keys-macos",title:"(KOR) VsCode Shortcut Keys[MacOS]",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/VsCode-Shortcut-Keys/"}},{id:"post-eng-development-of-artificial-intelligence",title:"(ENG) Development of Artificial Intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/history-of-ML/"}},{id:"post-kor-\ub9c8\ud06c\ub2e4\uc6b4-\ubb38\ubc95-\uc815\ub9ac",title:"(KOR) \ub9c8\ud06c\ub2e4\uc6b4 \ubb38\ubc95 \uc815\ub9ac",description:"\ub9c8\ud06c\ub2e4\uc6b4 \ubb38\ubc95",section:"Posts",handler:()=>{window.location.href="/blog/2024/markdown-syntax/"}},{id:"post-eng-backpropagation",title:"(ENG) Backpropagation",description:"backpropagation",section:"Posts",handler:()=>{window.location.href="/blog/2024/backpropagation/"}},{id:"post-eng-github-commit-message-conventions",title:"(ENG) Github Commit Message Conventions",description:"gitub commmit message convetions",section:"Posts",handler:()=>{window.location.href="/blog/2024/github-conventions-copy/"}},{id:"post-kor-\ub17c\ubb38-\ub9ac\ubdf0-\ubc29\ubc95\ub860",title:"(KOR) \ub17c\ubb38 \ub9ac\ubdf0 \ubc29\ubc95\ub860",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/journal-reading-methodology/"}},{id:"post-kor-\uc544\ub098\ucf58\ub2e4-venv-\uc124\uc815",title:"(KOR) \uc544\ub098\ucf58\ub2e4 venv \uc124\uc815",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/conda-venv/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-\uc791\uc131\uc911-2025-snu-nlp-lab-winter-internship",title:"(\uc791\uc131\uc911)2025 SNU NLP Lab Winter Internship",description:"2025 \uc11c\uc6b8\ub300\ud559\uad50 \uc790\uc5f0\uc5b4\ucc98\ub9ac \uc5f0\uad6c\uc2e4 \ud65c\ub3d9 \uc815\ub9ac",section:"Projects",handler:()=>{window.location.href="/projects/project1/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>